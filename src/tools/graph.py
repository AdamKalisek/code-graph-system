"""Graph export/import utilities built on pipeline configuration."""

from __future__ import annotations

import hashlib
import json
import logging
import sqlite3
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple

from neo4j import GraphDatabase
from neo4j.exceptions import Neo4jError, ServiceUnavailable

from src.pipeline import PipelineConfig, Neo4jConfig

logger = logging.getLogger(__name__)


# ---------------------------------------------------------------------------
# Exporter
# ---------------------------------------------------------------------------


@dataclass
class GraphExporter:
    config: PipelineConfig
    output_path: Path
    include_file_structure: bool = True

    def export_cypher(self) -> Dict[str, int]:
        sqlite_path = self.config.storage.sqlite_path
        if not sqlite_path.exists():
            raise FileNotFoundError(f"SQLite database not found: {sqlite_path}")

        conn = sqlite3.connect(str(sqlite_path))
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute("SELECT * FROM symbols")
        symbols = cursor.fetchall()
        cursor.execute("SELECT * FROM symbol_references")
        references = cursor.fetchall()

        project_root = self.config.project.root.resolve()

        stats = {
            "symbols": len(symbols),
            "references": len(references),
        }

        directories: Dict[str, str] = {}
        files: Dict[str, str] = {}
        file_to_symbols: Dict[str, List[str]] = {}

        if self.include_file_structure:
            for row in symbols:
                file_path = row["file_path"]
                if not file_path:
                    continue

                path_obj = Path(file_path)
                rel_path = _make_relative(path_obj, project_root)
                symbol_type = row["type"]

                if symbol_type == "directory":
                    directories.setdefault(rel_path, _hash_id(rel_path))
                else:
                    files.setdefault(rel_path, _hash_id(rel_path))
                    file_to_symbols.setdefault(rel_path, []).append(row["id"])

                # build directory tree for this path
                parts = rel_path.split('/')
                for i in range(1, len(parts)):
                    dir_path = '/'.join(parts[:i])
                    directories.setdefault(dir_path, _hash_id(dir_path))

            stats["directories"] = len(directories)
            stats["files"] = len(files)

        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        with self.output_path.open('w', encoding='utf-8') as f:
            f.write("// Generated by GraphExporter\n")
            f.write("MATCH (n) DETACH DELETE n;\n\n")

            # Indexes / constraints
            f.write("// Indexes\n")
            index_statements = [
                "CREATE CONSTRAINT IF NOT EXISTS FOR (s:Symbol) REQUIRE s.id IS UNIQUE;",
                "CREATE CONSTRAINT IF NOT EXISTS FOR (f:File) REQUIRE f.id IS UNIQUE;",
                "CREATE CONSTRAINT IF NOT EXISTS FOR (d:Directory) REQUIRE d.id IS UNIQUE;",
                "CREATE INDEX IF NOT EXISTS FOR (c:Class) ON (c.name);",
                "CREATE INDEX IF NOT EXISTS FOR (m:Method) ON (m.name);",
                "CREATE INDEX IF NOT EXISTS FOR (f:Function) ON (f.name);",
            ]
            for stmt in index_statements:
                f.write(stmt + "\n")
            f.write("\n")

            if self.include_file_structure:
                _write_directory_nodes(f, directories)
                _write_file_nodes(f, files)

            _write_symbol_nodes(f, symbols, project_root)

            if self.include_file_structure:
                _write_directory_relationships(f, directories)
                _write_directory_file_relationships(f, directories, files)
                _write_file_symbol_relationships(f, files, file_to_symbols)

            _write_symbol_relationships(f, references)

        conn.close()
        logger.info("Wrote Cypher export to %s", self.output_path)
        return stats


def _make_relative(path_obj: Path, project_root: Path) -> str:
    try:
        rel = path_obj.resolve().relative_to(project_root)
    except ValueError:
        rel = path_obj.name
    return str(rel).replace('\\', '/')


def _hash_id(text: str) -> str:
    return hashlib.md5(text.encode()).hexdigest()


def _write_directory_nodes(file, directories: Dict[str, str]) -> None:
    if not directories:
        return
    file.write("// Directory nodes\n")
    for path, dir_id in sorted(directories.items()):
        name = path.split('/')[-1] if '/' in path else path
        safe_path = path.replace("'", "\\'")
        safe_name = name.replace("'", "\\'")
        file.write(
            f"CREATE (:Directory {{id: '{dir_id}', path: '{safe_path}', name: '{safe_name}'}});\n"
        )
    file.write("\n")


def _write_file_nodes(file, files: Dict[str, str]) -> None:
    if not files:
        return
    file.write("// File nodes\n")
    for path, file_id in sorted(files.items()):
        name = path.split('/')[-1]
        ext = name.split('.')[-1] if '.' in name else ''
        safe_path = path.replace("'", "\\'")
        safe_name = name.replace("'", "\\'")
        file.write(
            f"CREATE (:File {{id: '{file_id}', path: '{safe_path}', name: '{safe_name}', extension: '{ext}'}});\n"
        )
    file.write("\n")


def _write_symbol_nodes(file, symbols: Iterable[sqlite3.Row], project_root: Path) -> None:
    file.write("// Symbol nodes\n")
    for row in symbols:
        labels = _labels_for_symbol(row)
        props = {
            "id": row["id"],
            "name": row["name"],
            "type": row["type"],
        }
        if row["file_path"]:
            props["file"] = _make_relative(Path(row["file_path"]), project_root)
        if row["line_number"]:
            props["line"] = row["line_number"]
        if row["namespace"]:
            props["namespace"] = row["namespace"]

        safe_props = {k: _escape_prop(v) for k, v in props.items() if v is not None}
        props_str = ', '.join(f"{k}: {json.dumps(v)}" for k, v in safe_props.items())
        label_str = ':'.join(labels)
        file.write(f"CREATE (:{label_str} {{{props_str}}});\n")
    file.write("\n")


def _labels_for_symbol(row: sqlite3.Row) -> List[str]:
    label_map = {
        'class': 'Class',
        'interface': 'Interface',
        'trait': 'Trait',
        'method': 'Method',
        'function': 'Function',
        'property': 'Property',
        'constant': 'Constant',
        'namespace': 'Namespace',
        'file': 'File',
        'directory': 'Directory',
    }
    symbol_type = row['type']
    labels = ['Symbol']
    extra = label_map.get(symbol_type)
    if extra:
        labels.append(extra)
    elif symbol_type and symbol_type.startswith('js_'):
        labels.append('JavaScript')
        labels.append(symbol_type.replace('js_', '').title())
    return labels


def _write_directory_relationships(file, directories: Dict[str, str]) -> None:
    if not directories:
        return
    file.write("// Directory hierarchy\n")
    for path, dir_id in sorted(directories.items()):
        if '/' not in path:
            continue
        parent_path = path.rsplit('/', 1)[0]
        parent_id = directories.get(parent_path)
        if parent_id:
            file.write(
                f"MATCH (p:Directory {{id: '{parent_id}'}}), (c:Directory {{id: '{dir_id}'}}) CREATE (p)-[:CONTAINS]->(c);\n"
            )
    file.write("\n")


def _write_directory_file_relationships(file, directories: Dict[str, str], files: Dict[str, str]) -> None:
    if not directories or not files:
        return
    file.write("// Directory -> File relationships\n")
    for path, file_id in files.items():
        if '/' not in path:
            continue
        parent_path = path.rsplit('/', 1)[0]
        dir_id = directories.get(parent_path)
        if dir_id:
            file.write(
                f"MATCH (d:Directory {{id: '{dir_id}'}}), (f:File {{id: '{file_id}'}}) CREATE (d)-[:CONTAINS]->(f);\n"
            )
    file.write("\n")


def _write_file_symbol_relationships(file, files: Dict[str, str], file_to_symbols: Dict[str, List[str]]) -> None:
    if not files:
        return
    file.write("// File -> Symbol relationships\n")
    for path, symbol_ids in file_to_symbols.items():
        file_id = files[path]
        for symbol_id in symbol_ids:
            file.write(
                f"MATCH (f:File {{id: '{file_id}'}}), (s {{id: '{symbol_id}'}}) CREATE (f)-[:DEFINES]->(s);\n"
            )
    file.write("\n")


def _write_symbol_relationships(file, references: Iterable[sqlite3.Row]) -> None:
    file.write("// Symbol relationships\n")
    for ref in references:
        rel_type = ref['reference_type'].replace('-', '_').upper()
        file.write(
            f"MATCH (s {{id: '{ref['source_id']}'}}), (t {{id: '{ref['target_id']}'}}) CREATE (s)-[:{rel_type}]->(t);\n"
        )


def _escape_prop(value) -> object:
    if isinstance(value, str):
        return value.replace("\\", "\\\\")
    return value


# ---------------------------------------------------------------------------
# Importer
# ---------------------------------------------------------------------------


@dataclass
class GraphImporter:
    neo4j_config: Neo4jConfig
    sqlite_path: Path
    clear_first: bool = True
    batch_nodes: int = 10000
    batch_relationships: int = 5000

    def run(self) -> Dict[str, int]:
        if not self.sqlite_path.exists():
            raise FileNotFoundError(f"SQLite database not found: {self.sqlite_path}")

        driver = GraphDatabase.driver(
            self.neo4j_config.uri,
            auth=(self.neo4j_config.username, self.neo4j_config.password),
        )
        stats = {
            'nodes_created': 0,
            'relationships_created': 0,
            'failed_relationships': 0,
        }

        try:
            if self.clear_first:
                _clear_database(driver, self.neo4j_config.database)

            _create_import_constraints(driver, self.neo4j_config.database)

            node_count = _import_nodes(
                driver,
                self.neo4j_config.database,
                self.sqlite_path,
                self.batch_nodes,
            )
            stats['nodes_created'] = node_count

            rel_count, failed = _import_relationships(
                driver,
                self.neo4j_config.database,
                self.sqlite_path,
                self.batch_relationships,
            )
            stats['relationships_created'] = rel_count
            stats['failed_relationships'] = failed

        finally:
            driver.close()

        return stats


def _clear_database(driver, database: str) -> None:
    logger.info("Clearing Neo4j database %s", database)
    with driver.session(database=database) as session:
        while True:
            result = session.run(
                """
                MATCH (n)
                WITH n LIMIT 10000
                DETACH DELETE n
                RETURN COUNT(n) AS deleted
                """
            )
            deleted = result.single()["deleted"]
            if deleted == 0:
                break
            logger.debug("Deleted batch of %s nodes", deleted)


def _create_import_constraints(driver, database: str) -> None:
    statements = [
        "CREATE CONSTRAINT symbol_id IF NOT EXISTS FOR (s:Symbol) REQUIRE s.id IS UNIQUE",
        "CREATE CONSTRAINT file_id IF NOT EXISTS FOR (f:File) REQUIRE f.id IS UNIQUE",
        "CREATE CONSTRAINT dir_id IF NOT EXISTS FOR (d:Directory) REQUIRE d.id IS UNIQUE",
        "CREATE CONSTRAINT php_class_id IF NOT EXISTS FOR (c:PHPClass) REQUIRE c.id IS UNIQUE",
        "CREATE CONSTRAINT php_method_id IF NOT EXISTS FOR (m:PHPMethod) REQUIRE m.id IS UNIQUE",
        "CREATE CONSTRAINT php_property_id IF NOT EXISTS FOR (p:PHPProperty) REQUIRE p.id IS UNIQUE",
        "CREATE CONSTRAINT php_function_id IF NOT EXISTS FOR (f:PHPFunction) REQUIRE f.id IS UNIQUE",
    ]
    with driver.session(database=database) as session:
        for stmt in statements:
            try:
                session.run(stmt)
            except Neo4jError as exc:
                if "already exists" not in str(exc):
                    logger.warning("Constraint creation issue: %s", exc)


def _import_nodes(driver, database: str, sqlite_path: Path, batch_size: int) -> int:
    conn = sqlite3.connect(str(sqlite_path))
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) as count FROM symbols")
    total = cursor.fetchone()['count']

    created = 0
    offset = 0
    with driver.session(database=database) as session:
        while offset < total:
            cursor.execute(
                "SELECT * FROM symbols LIMIT ? OFFSET ?",
                (batch_size, offset),
            )
            rows = cursor.fetchall()
            if not rows:
                break

            grouped: Dict[str, List[Dict[str, object]]] = {}
            for row in rows:
                labels = ':'.join(_labels_for_symbol(row))
                grouped.setdefault(labels, []).append(_node_properties(row))

            for label_combo, props_list in grouped.items():
                query = f"""
                UNWIND $batch AS props
                CREATE (n:{label_combo})
                SET n = props
                """
                session.run(query, batch=props_list)
                created += len(props_list)

            offset += batch_size
            logger.debug("Imported nodes %s/%s", min(offset, total), total)

    conn.close()
    return created


def _node_properties(row: sqlite3.Row) -> Dict[str, object]:
    props = {
        'id': row['id'],
        'name': row['name'],
        'type': row['type'],
    }
    optional = [
        'file_path',
        'line_number',
        'namespace',
        'visibility',
        'is_static',
        'is_abstract',
        'is_final',
        'return_type',
        'extends',
        'implements',
    ]
    for key in optional:
        value = row[key]
        if value is not None:
            props[key] = value
    return props


def _import_relationships(
    driver,
    database: str,
    sqlite_path: Path,
    batch_size: int,
) -> Tuple[int, int]:
    conn = sqlite3.connect(str(sqlite_path))
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute(
        """
        SELECT reference_type, COUNT(*) as count
        FROM symbol_references
        GROUP BY reference_type
        """
    )
    rel_counts = cursor.fetchall()

    created = 0
    failed = 0

    with driver.session(database=database) as session:
        for rel_row in rel_counts:
            rel_type = rel_row['reference_type']
            total = rel_row['count']
            offset = 0
            while True:
                cursor.execute(
                    """
                    SELECT source_id, target_id, line_number, column_number
                    FROM symbol_references
                    WHERE reference_type = ?
                    LIMIT ? OFFSET ?
                    """,
                    (rel_type, batch_size, offset),
                )
                rows = cursor.fetchall()
                if not rows:
                    break

                payload = [
                    {
                        'source_id': row['source_id'],
                        'target_id': row['target_id'],
                        'line': row['line_number'],
                        'column': row['column_number'],
                    }
                    for row in rows
                ]

                query = f"""
                UNWIND $batch AS rel
                MATCH (s {{id: rel.source_id}})
                MATCH (t {{id: rel.target_id}})
                CREATE (s)-[r:{rel_type.replace('-', '_').upper()}]->(t)
                SET r.line = rel.line, r.column = rel.column
                """
                try:
                    session.run(query, batch=payload)
                    created += len(payload)
                except Neo4jError as exc:
                    logger.error(
                        "Failed relationship batch for %s at offset %s: %s",
                        rel_type,
                        offset,
                        exc,
                    )
                    failed += len(payload)

                offset += batch_size
                logger.debug(
                    "Imported %s relationships of type %s", min(offset, total), rel_type
                )

    conn.close()
    return created, failed
